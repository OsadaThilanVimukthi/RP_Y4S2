{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': '../testing-images/Belly Rot/Belly Rot (1).jpg', 'predicted_class': 'Cabbage'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n",
    "\n",
    "VGG_types = {\n",
    "    \"VGG16\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes=2):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = input_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types['VGG16'])  # create our conv layers\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes)  # sizeInputImage = 224, divided by num Maxpool : 224 / 2‚Å∑ = 7\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)  # flatten our convlayers\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        for layer in architecture:\n",
    "            if type(layer) is int:\n",
    "                out_channels = layer\n",
    "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                    kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                            nn.BatchNorm2d(layer),\n",
    "                            nn.ReLU()]\n",
    "                in_channels = layer  # for the next iteration\n",
    "            elif layer == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "        return nn.Sequential(*layers,)\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model_path = '../fun2/VGG16_torch_model.pt'\n",
    "model = VGG_net(input_channels=3, num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation for input images\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Function to predict and return the results for a single image\n",
    "def predict_single_image(image_path, model, class_names):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image_tensor = data_transform(image).unsqueeze(0)\n",
    "\n",
    "        # Check if GPU is available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Move the input tensor to the appropriate device\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            output = model(image_tensor)\n",
    "\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'predicted_class': class_names[predicted_class.item()]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Example usage for a single image\n",
    "image_path = '../testing-images/Belly Rot/Belly Rot (1).jpg'\n",
    "result = predict_single_image(image_path, model, class_names)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cucumber-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
