{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex181uPxrKp6"
      },
      "source": [
        "# ML Model Development - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHiKUyNjrMfU",
        "outputId": "d857afec-f15f-46c3-e734-90fc657ebfc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyagb20yrKp9",
        "outputId": "dcbfe050-4786-4c74-b2ed-0d0f60467791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14979909 (57.14 MB)\n",
            "Trainable params: 14979909 (57.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Found 5200 images belonging to 5 classes.\n",
            "Found 1300 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 1.4295 - accuracy: 0.3379 \n",
            "Epoch 1: val_loss improved from inf to 0.79847, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r163/163 [==============================] - 2388s 14s/step - loss: 1.4295 - accuracy: 0.3379 - val_loss: 0.7985 - val_accuracy: 0.7485\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.7917\n",
            "Epoch 2: val_loss improved from 0.79847 to 0.35222, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n",
            "163/163 [==============================] - 1695s 10s/step - loss: 0.5709 - accuracy: 0.7917 - val_loss: 0.3522 - val_accuracy: 0.8662\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9317\n",
            "Epoch 3: val_loss improved from 0.35222 to 0.24282, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n",
            "163/163 [==============================] - 1620s 10s/step - loss: 0.2044 - accuracy: 0.9317 - val_loss: 0.2428 - val_accuracy: 0.9100\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9373\n",
            "Epoch 4: val_loss did not improve from 0.24282\n",
            "163/163 [==============================] - 1498s 9s/step - loss: 0.1806 - accuracy: 0.9373 - val_loss: 0.3381 - val_accuracy: 0.8785\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9344\n",
            "Epoch 5: val_loss did not improve from 0.24282\n",
            "163/163 [==============================] - 1406s 9s/step - loss: 0.1917 - accuracy: 0.9344 - val_loss: 0.4369 - val_accuracy: 0.8869\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9537\n",
            "Epoch 6: val_loss improved from 0.24282 to 0.08878, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n",
            "163/163 [==============================] - 1423s 9s/step - loss: 0.1435 - accuracy: 0.9537 - val_loss: 0.0888 - val_accuracy: 0.9731\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9715\n",
            "Epoch 7: val_loss did not improve from 0.08878\n",
            "163/163 [==============================] - 1450s 9s/step - loss: 0.0812 - accuracy: 0.9715 - val_loss: 0.1521 - val_accuracy: 0.9515\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9740\n",
            "Epoch 8: val_loss did not improve from 0.08878\n",
            "163/163 [==============================] - 1418s 9s/step - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.1051 - val_accuracy: 0.9700\n",
            "Epoch 9/10\n",
            " 33/163 [=====>........................] - ETA: 9:21 - loss: 0.0514 - accuracy: 0.9830"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define path to dataset directory\n",
        "# drive_dataset_dir = \"/content/drive/MyDrive/RP_Models_Y4S2/Cucumber/Function3/LeafDiseaseDataV2.0Aug\"\n",
        "# dataset_dir = \"/content/LeavesDatasetAug\"\n",
        "\n",
        "# # Copy the entire directory to the new location\n",
        "# shutil.copytree(drive_dataset_dir, dataset_dir)\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/RP_Models_Y4S2/Cucumber/Function3/LeafDiseaseDataV2.0Aug\"\n",
        "\n",
        "# Define image size for resizing\n",
        "image_size = (224, 224)  # Use 224x224 for VGG16\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(os.listdir(dataset_dir))\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=30,  # Increased rotation range\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,  # Added shear range\n",
        "    zoom_range=0.2,  # Added zoom range\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the pre-trained model (VGG16)\n",
        "base_model = VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(*image_size, 3)\n",
        ")\n",
        "\n",
        "# Add custom layers for classification with dropout\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)  # Reduced dense layer size\n",
        "x = Dropout(0.5)(x)  # Increased dropout rate\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n",
        "\n",
        "# Create data generators for training and validation\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# Define a model checkpoint to save the best model in \".h5\" format\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/RP_Models_Y4S2/Cucumber/Function3/best_model.h5\", save_best_only=True, verbose=1)\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Train the model with increased epochs\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]  # Save the best model and early stopping\n",
        ")\n",
        "\n",
        "# Load the best model for evaluation\n",
        "best_model = keras.models.load_model(\"/content/drive/MyDrive/RP_Models_Y4S2/Cucumber/Function3/best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "valid_generator.reset()\n",
        "valid_loss, valid_accuracy = best_model.evaluate(valid_generator)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Validation Loss: {valid_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93L7OmjFrKp_"
      },
      "source": [
        "###  Plots for accuracy and loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3HMlmDWrKp_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq-E2S7zrKp_"
      },
      "source": [
        "## VGG16 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Vn7zcfrKqA"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "best_model = keras.models.load_model(\"/content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "valid_generator.reset()\n",
        "valid_loss, valid_accuracy = best_model.evaluate(valid_generator)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Validation Loss: {valid_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Extract the history for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use 'history' from the training process to access loss and accuracy values\n",
        "train_loss = history.history['loss']\n",
        "valid_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "valid_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
        "plt.plot(range(1, len(valid_loss) + 1), valid_loss, label='Validation Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(122)\n",
        "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, len(valid_accuracy) + 1), valid_accuracy, label='Validation Accuracy')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAXyRT5LrKqA"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp5T80kLrKqA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get the true labels for the validation dataset\n",
        "true_labels = valid_generator.classes\n",
        "\n",
        "# Generate predictions for the validation dataset using the best model\n",
        "valid_generator.reset()\n",
        "predicted_probabilities = best_model.predict(valid_generator)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "TP = cm[1, 1]\n",
        "TN = cm[0, 0]\n",
        "FP = cm[0, 1]\n",
        "FN = cm[1, 0]\n",
        "\n",
        "# Get class names\n",
        "class_names = list(valid_generator.class_indices.keys())\n",
        "\n",
        "# Print the confusion matrix, TP, TN, FP, FN, and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "print(\"\\nClass Names:\")\n",
        "print(class_names)\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
