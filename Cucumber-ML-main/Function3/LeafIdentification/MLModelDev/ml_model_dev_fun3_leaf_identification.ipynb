{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex181uPxrKp6"
      },
      "source": [
        "# ML Model Development - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHiKUyNjrMfU",
        "outputId": "6837bf70-0e3d-4414-c52b-4005eeeec023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define path to dataset directory\n",
        "# drive_dataset_dir = \"/content/drive/MyDrive/silverline/Cucumber/Function3/LeavesDatasetAug\"\n",
        "# dataset_dir = \"/content/LeavesDatasetAug\"\n",
        "\n",
        "# # Copy the entire directory to the new location\n",
        "# shutil.copytree(drive_dataset_dir, dataset_dir)\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/silverline/Cucumber/Function3/LeavesDatasetAug\"\n",
        "\n",
        "# Define image size for resizing\n",
        "image_size = (224, 224)  # Use 224x224 for VGG16\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(os.listdir(dataset_dir))\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=30,  # Increased rotation range\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,  # Added shear range\n",
        "    zoom_range=0.2,  # Added zoom range\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the pre-trained model (VGG16)\n",
        "base_model = VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(*image_size, 3)\n",
        ")\n",
        "\n",
        "# Add custom layers for classification with dropout\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)  # Reduced dense layer size\n",
        "x = Dropout(0.5)(x)  # Increased dropout rate\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n",
        "\n",
        "# Create data generators for training and validation\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SM_lw4LvaA2",
        "outputId": "2a134e66-4682-4fc5-c87f-215e015b6309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14978370 (57.14 MB)\n",
            "Trainable params: 14978370 (57.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Found 5118 images belonging to 2 classes.\n",
            "Found 1278 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyagb20yrKp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e576460-c12a-4833-c514-ec3652abaf92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14978370 (57.14 MB)\n",
            "Trainable params: 14978370 (57.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Found 5118 images belonging to 2 classes.\n",
            "Found 1278 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9193\n",
            "Epoch 1: val_loss improved from inf to 0.14644, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 2091s 11s/step - loss: 0.1788 - accuracy: 0.9193 - val_loss: 0.1464 - val_accuracy: 0.9593\n",
            "Epoch 2/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9863\n",
            "Epoch 2: val_loss improved from 0.14644 to 0.00980, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n",
            "160/160 [==============================] - 1603s 10s/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
            "Epoch 3/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9977\n",
            "Epoch 3: val_loss did not improve from 0.00980\n",
            "160/160 [==============================] - 1517s 10s/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0139 - val_accuracy: 0.9937\n",
            "Epoch 4/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9889\n",
            "Epoch 4: val_loss did not improve from 0.00980\n",
            "160/160 [==============================] - 1512s 9s/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0194 - val_accuracy: 0.9937\n",
            "Epoch 5/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9920\n",
            "Epoch 5: val_loss did not improve from 0.00980\n",
            "160/160 [==============================] - 1538s 10s/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0138 - val_accuracy: 0.9953\n",
            "Epoch 6/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980\n",
            "Epoch 6: val_loss improved from 0.00980 to 0.00030, saving model to /content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\n",
            "160/160 [==============================] - 1534s 10s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 3.0235e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 6.9896e-04 - accuracy: 0.9996\n",
            "Epoch 7: val_loss did not improve from 0.00030\n",
            "160/160 [==============================] - 1600s 10s/step - loss: 6.9896e-04 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 8/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9971\n",
            "Epoch 8: val_loss did not improve from 0.00030\n",
            "160/160 [==============================] - 1487s 9s/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0097 - val_accuracy: 0.9961\n",
            "Epoch 9/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9947\n",
            "Epoch 9: val_loss did not improve from 0.00030\n",
            "160/160 [==============================] - 1491s 9s/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9937\n",
            "Epoch 10/30\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9963\n",
            "Epoch 10: val_loss did not improve from 0.00030\n",
            "160/160 [==============================] - 1566s 10s/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
            "Epoch 11/30\n",
            "147/160 [==========================>...] - ETA: 1:29 - loss: 0.0136 - accuracy: 0.9955"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define path to dataset directory\n",
        "# drive_dataset_dir = \"/content/drive/MyDrive/silverline/Cucumber/Function3/LeavesDatasetAug\"\n",
        "# dataset_dir = \"/content/LeavesDatasetAug\"\n",
        "\n",
        "# # Copy the entire directory to the new location\n",
        "# shutil.copytree(drive_dataset_dir, dataset_dir)\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/silverline/Cucumber/Function3/LeavesDatasetAug\"\n",
        "\n",
        "# Define image size for resizing\n",
        "image_size = (224, 224)  # Use 224x224 for VGG16\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(os.listdir(dataset_dir))\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=30,  # Increased rotation range\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,  # Added shear range\n",
        "    zoom_range=0.2,  # Added zoom range\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the pre-trained model (VGG16)\n",
        "base_model = VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(*image_size, 3)\n",
        ")\n",
        "\n",
        "# Add custom layers for classification with dropout\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)  # Reduced dense layer size\n",
        "x = Dropout(0.5)(x)  # Increased dropout rate\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n",
        "\n",
        "# Create data generators for training and validation\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# Define a model checkpoint to save the best model in \".h5\" format\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\", save_best_only=True, verbose=1)\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Train the model with increased epochs\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]  # Save the best model and early stopping\n",
        ")\n",
        "\n",
        "# Load the best model for evaluation\n",
        "best_model = keras.models.load_model(\"/content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "valid_generator.reset()\n",
        "valid_loss, valid_accuracy = best_model.evaluate(valid_generator)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Validation Loss: {valid_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93L7OmjFrKp_"
      },
      "source": [
        "###  Plots for accuracy and loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3HMlmDWrKp_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq-E2S7zrKp_"
      },
      "source": [
        "## VGG16 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Vn7zcfrKqA",
        "outputId": "ea0db3ab-d151-4131-9803-95f393e24994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 1730s 44s/step - loss: 2.8765e-04 - accuracy: 1.0000\n",
            "Found 1278 images belonging to 2 classes.\n",
            "40/40 [==============================] - 867s 22s/step - loss: 4.9720e-04 - accuracy: 1.0000\n",
            "Validation Loss: 0.0003\n",
            "Validation Accuracy: 100.00%\n",
            "Test Loss: 0.0005\n",
            "Test Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-74bde93a39d3>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Use 'history' from the training process to access loss and accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "best_model = keras.models.load_model(\"/content/drive/MyDrive/silverline/Cucumber/Function3/best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "valid_generator.reset()\n",
        "valid_loss, valid_accuracy = best_model.evaluate(valid_generator)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Validation Loss: {valid_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Extract the history for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use 'history' from the training process to access loss and accuracy values\n",
        "train_loss = history.history['loss']\n",
        "valid_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "valid_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
        "plt.plot(range(1, len(valid_loss) + 1), valid_loss, label='Validation Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(122)\n",
        "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, len(valid_accuracy) + 1), valid_accuracy, label='Validation Accuracy')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAXyRT5LrKqA"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp5T80kLrKqA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get the true labels for the validation dataset\n",
        "true_labels = valid_generator.classes\n",
        "\n",
        "# Generate predictions for the validation dataset using the best model\n",
        "valid_generator.reset()\n",
        "predicted_probabilities = best_model.predict(valid_generator)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "TP = cm[1, 1]\n",
        "TN = cm[0, 0]\n",
        "FP = cm[0, 1]\n",
        "FN = cm[1, 0]\n",
        "\n",
        "# Get class names\n",
        "class_names = list(valid_generator.class_indices.keys())\n",
        "\n",
        "# Print the confusion matrix, TP, TN, FP, FN, and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "print(\"\\nClass Names:\")\n",
        "print(class_names)\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}